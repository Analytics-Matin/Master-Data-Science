{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aprendizaje, Generalización y Sobreajuste\n",
    "## Validación cruzada\n",
    "### Grupo de Meteorología de Santander\n",
    "### 22 Nov 2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Introducción"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelos de aprendizaje\n",
    "\n",
    "Para que un problema sea adecuado para su resolución mediante técnicas de aprendizaje automático la condición fundamental es la existencia de datos para alimentar (entrenar) el algoritmo de aprendizaje.\n",
    "\n",
    "De esta forma, a partir de un conjunto de datos de entrenamiento que se considera representativo de la distribución que se quiere modelar, nuestro modelo de aprendizaje viene dado por:\n",
    "\n",
    "* El **algoritmo usado** para aprender el patrón y \n",
    "* La familia de **funciones** \n",
    "* Los **datos** que utilicemos para aproximar el patrón a aprender. \n",
    "\n",
    "De este modo, el proceso de aprendizaje dependerá de estos tres elementos, los cuales establecerán nuestras limitaciones e incertidumbres a la hora tanto de aprender el patrón como de realizar predicciones con el patrón aprendido.\n",
    "\n",
    "## Generalización y sobreajuste\n",
    "\n",
    "Recordemos que el objetivo principal del modelo aprendido es que tenga **la capacidad de generalizar**, es decir, la capacidad de funcionar bien para nuevos datos que no forman parte de la muestra de entrenamiento (por ejemplo, una muestra de datos de test). En caso contario, diremos que el modelo está **sobreajustado a la muestra de entrenamiento**. \n",
    "\n",
    "**La introducción de grados de libertad en la familia de funciones consideradas en el aprendizaje suele dar lugar a modelos sobreajustados**, por lo que suele ser conveniente partir de los modelos más simples e ir introduciendo grados de libertad progresivamente si fuera necesario.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta práctica utilizaremos...\n",
    "\n",
    "* modelo: Regresion lineal\n",
    "* Dataset: Auto (paquete ISLR)\n",
    "* Validación: error medio absoluto (MAE) y error cuadrático medio (MSE)\n",
    "* Librerías de R:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(ISLR)\n",
    "library(caret)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Carga y transformación de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El dataset Auto (paquete `ISLR`) contiene información sobre las características de 392 vehículos. Puede verse una descripción detallada del conjunto de datos mediante: `help(\"Auto\", package = \"ISLR\")`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data(Auto)\n",
    "str(Auto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Conversión de libras a Kg\n",
    "Auto$weight <- Auto$weight * 0.453592"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comenzamos con un análisis preliminar de nuestros datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs(Auto)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este ejemplo solo nos interesa la relación entre el peso (weight) y la potencia (horsepower).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs(weight ~ horsepower, data = Auto, col = c(\"orange\", \"green3\", \"blue\")[unclass(Auto$origin)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Supuesto:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imaginemos que una empresa X nos proporciona únicamente los registros o datos europeos para que obtengamos un modelo capaz de estimar los pesos de los coches americanos en función de la potencia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejecutar esto una sola vez\n",
    "Auto$origin <- as.character(factor(Auto$origin, labels = c(\"American\", \"Japanese\", \"European\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# muestra de test\n",
    "america <- Auto[Auto$origin == \"American\", ]\n",
    "# muestra de train\n",
    "europe <- Auto[Auto$origin == \"European\", ]\n",
    "str(america); str(europe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualicemos ambos subconjuntos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(america$horsepower, america$weight, \n",
    "     xlab = \"horsepower\", ylab = \"weight\",\n",
    "     pch = 16, col = \"red\",\n",
    "     xlim = range(Auto$horsepower))\n",
    "points(europe$horsepower, europe$weight, pch = 16)\n",
    "# La función `lm` realiza el ajuste de un modelo lineal entre ambas variables:\n",
    "abline(lm(weight~horsepower, data = america), col = \"red\")\n",
    "abline(lm(weight~horsepower, data = europe))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Definición de las funciones de error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación se definen las funciones que se van a emplear para determinar el error del modelo, y que será el error medio absoluto (*mean absolute error*, $MAE$) y el error cuadrático medio (*root mean square error*, $RMSE$):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Error Functions:\n",
    "mae <- function(obs, est) {\n",
    "  mean(abs(obs - est))\n",
    "}\n",
    "\n",
    "rmse <- function(obs, est) {\n",
    "  sqrt(mean((obs - est)^2))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 Construcción del modelo y evaluación\n",
    "\n",
    "## 4.1 Contrucción del modelo sin validación cruzada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La función `lm` del paquete básico `stats` realiza el ajuste del modelo lineal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg <- lm(weight ~ horsepower, data = europe) \n",
    "summary(reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se extraen los valores ajustados por el modelo (\"fitted values\") de `reg`, es decir, el resultado de la applicación del modelo ajustado a los propios datos de entrenamiento `yest`, para comparar la estimación (o predicción) del modelo con los datos reales (observados):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yest <- reg$fitted.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "**Nota**: Este procedimiento es idéntico (salvando posibles errores de redondeo) a utilizar nuestro modelo para predecir la respuesta (*weight*) en función del predictor (*horsepower*), empleando exactamente el mismo subcontunto que se utilizó en el proceso de entrenamiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yest_bis <- predict(object = reg, newdata = data.frame(horsepower = europe$horsepower))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(europe$weight, type = 'l')\n",
    "lines(yest, col = 'blue')\n",
    "legend(\"topleft\", c(\"obs\",\"pred\"), lty=1, col = c(\"black\", \"blue\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por último, se calcula el error de la estimación (MAE y RMSE):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae(obs = europe$weight, yest)\n",
    "rmse(obs = europe$weight, yest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adicionalmente, la correlación proporciona otra medida del error, relacionada con la *asociación* entre las series observada y predicha:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cor(europe$weight, yest, method = \"spearman\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "El ejercicio anterior utiliza todos los datos para entrenar y validar el modelo. Es decir, la validación se realiza utilizando como conjunto de validación el mismo conjunto utilizado como \"train\" (conjunto de entrenamiento). Por lo tanto no podemos estimar la capacidad de generalización o sobreajuste del modelo. \n",
    "\n",
    "Si la validación se realiza sobre un conjunto independiente de la muestra de entrenamiento el error esperable es mayor. Ilustraremos esto con los siguientes ejemplos:\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Construcción del modelo y validación *hold-out* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El modo más básico de analizar el error de mi modelo es dividiendo la muestra en subconjuntos disjuntos (hold out). En este primer caso consideraremos sólo dos conjuntos, uno de train y otro de validación con la mitad de datos (instancias, i.e. filas) en cada uno. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n <- nrow(europe)\n",
    "ind <- order(europe$horsepower)[1:ceiling(n/2)]\n",
    "europe.train <- europe[ind, ]\n",
    "europe.val <- europe[-ind,]\n",
    "\n",
    "plot(america$horsepower, america$weight, \n",
    "     xlab = \"horsepower\", ylab = \"weight\",\n",
    "     pch = 16, col = \"red\",\n",
    "     xlim = range(Auto$horsepower))\n",
    "points(europe.train$horsepower, europe.train$weight, pch = 16, col = \"black\")\n",
    "points(europe.val$horsepower, europe.val$weight, pch = 21, bg = \"white\", cex = 0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplicamos de nuevo las funciones `lm` (para ajustar el modelo) y  `predict` (para aplicar el modelo sobre los datos de \"train\" y de \"validación\") y calculamos el RMSE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg0 <- lm(weight~horsepower, data = europe.train)\n",
    "yest0.train <- predict(reg0, newdata = data.frame(horsepower = europe.train$horsepower))\n",
    "yest0.val <- predict(reg0, newdata = data.frame(horsepower = europe.val$horsepower))\n",
    "rmse(europe.train$weight, yest0.train)\n",
    "rmse(europe.val$weight, yest0.val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "Como resulta obvio, Hemos entrenado con los valores de horsepower menores, por lo que **nuestra muestra no es representativa de la población**. \n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.1 Muestreo aleatiorio para obtener las muestras de train y de validación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para intentar minimizar el sesgo de nuestra muestra de entrenamiento, una solución es aleatorizar la selección. En este ejemplo utilizamos la función `sample` para obtener un índice de registros aleatoria. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n <- nrow(europe)\n",
    "set.seed(1)\n",
    "ind <- sample(1:n, ceiling(n/2))\n",
    "europe.train <- europe[ind, ]\n",
    "europe.val <- europe[-ind,]\n",
    "\n",
    "plot(america$horsepower, america$weight, \n",
    "     xlab = \"horsepower\", ylab = \"weight\",\n",
    "     pch = 16, col = \"red\",\n",
    "     xlim = range(Auto$horsepower))\n",
    "points(europe.train$horsepower, europe.train$weight, pch = 16, col = \"black\")\n",
    "points(europe.val$horsepower, europe.val$weight, pch = 21, bg = \"white\", cex = 0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplicamos de nuevo la funciones `lm` (para ajustar el modelo) y  `predict` (para aplicar el modelo sobre los datos de \"train\" y de \"validación\") y calculamos el RMSE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg1 <- lm(weight~horsepower, data = europe.train)\n",
    "yest1.train <- predict(reg1, newdata = data.frame(horsepower = europe.train$horsepower))\n",
    "yest1.val <- predict(reg1, newdata = data.frame(horsepower = europe.val$horsepower))\n",
    "rmse(europe.train$weight, yest1.train)\n",
    "rmse(europe.val$weight, yest1.val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "Al considerar una muestra representativa de la variabilidad de la población el error de validación es más bajo y se asemeja más al error de train que en el ejemplo anterior.\n",
    "\n",
    "**El modelo entrenado con una muestra aleatoria de `europe` tiene más capacidad de generalización** ya que:\n",
    "\n",
    "Decimos que existe sobreajuste cuando el error de train y el de validación son muy diferentes. Un modelo con capacidad de generalización, no sobreajustado, es aquel para el que ambos errores, en la muestra de entrenamiento y de test, son similares/comparables.\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A pesar de ello, esta metodología tiene dos inconvenientes potenciales:\n",
    "\n",
    " 1.- La estimación del error en el conjunto de validación puede variar mucho en función de la partición considerada:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(europe$horsepower, europe$weight, pch = \"*\")\n",
    "for (i in c(1:5)) {\n",
    "  ind <- sample(1:n, ceiling(n/2))\n",
    "  europe.train.i <- europe[ind, ]\n",
    "  europe.val.i <- europe[-ind, ]\n",
    "  reg.i <- lm(weight~horsepower, data = europe.train.i)\n",
    "  yest.val.i <- predict(reg.i, data.frame(horsepower = europe.val.i$horsepower))\n",
    "  abline(reg.i, lty = 2, col = \"grey30\")\n",
    "  message(\"RMSE fold \", i, \"= \",rmse(europe.val.i$weight, yest.val.i))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  2.- El error de validación puede ser sobreestimado. Dado que el modelo se entrena en un subconjunto de la muestra y que los métodos estadísticos suelen comportarse peor cuando son entrenados con pocos datos (n/2 = 40 en los ejemplos anteriores), esto puede dar lugar a una sobrestimación del error de validación respecto al obtenido considerando toda la muestra.\n",
    "\n",
    "La validación cruzada (cross-validación) que aplicaremos un poco más adelante considera estos dos problemas. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Modelización y cross-validación leave-one-out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como alternativa al muestreo aleatorio existe el método de validación cruzada denominado leave-one-out:\n",
    "\n",
    "* La selección de la muestra de entrenamiento NO se hace aleatoriamente, eliminando la variabilidad del error de validación.\n",
    "\n",
    "* La muestra de entrenamiento es la mayor posible que considera una muestra de validación.\n",
    "\n",
    "* Si un conjunto de datos tiene `N` registros, el ajuste del modelo se realiza con `N - 1` registros y el registro no considerado en el conjunto de entrenamiento se utiliza como validación o muestra independiente para validar el modelo.\n",
    "\n",
    "* Esta operación se repite `N` veces, así todos los registros del dataset se utilizan como dato de test para un modelo entrenado con el resto de registros.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind <- 1:n\n",
    "yest.2 <- numeric(length = length(ind))\n",
    "\n",
    "for (i in ind) {\n",
    "  Reg.i <- lm(weight~horsepower, data = europe, subset = ind[-i])\n",
    "  yest.2[i] <- predict(Reg.i, data.frame(horsepower = europe$horsepower[i]))\n",
    "}\n",
    "rmse(europe$weight, yest.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.1 Ejemplo anterior con la librería caret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctrl <- trainControl(method = \"LOOCV\")\n",
    "mod <- train(weight ~ horsepower,\n",
    "               data = europe,\n",
    "               method = \"lm\",\n",
    "               trControl = ctrl)\n",
    "mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod$results$RMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 Modelización y cross-validación k-fold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si el tamaño muestral es grande el método leave-one-out es computacionalmente costoso. Para evitar este coste surge otro método de validación cruzada: **El método k-fold** en el que se hace un leave-one-out por \"bloques\" o \"folds\": \n",
    "\n",
    "* se divide la muestra en `k` subconjuntos.\n",
    "\n",
    "* Se ajustan `k` modelos, considerando en cada caso un bloque como conjunto de validación y los `k-1` restantes como muestra de entrenamiento. \n",
    "\n",
    "* La estimación dependerá de como se realice la partición de los datos. La variabilidad mayor que en el caso del leave-one-out.\n",
    "\n",
    "* Con un número suficiente de subconjuntos, se obtienen los mismos resultados y conclusiones que las obtenidas con un leave-one-out. \n",
    "\n",
    "Consideramos el ejemplo anterior con 10 subconjuntos y vamos paso a paso.\n",
    "\n",
    "1) Dividimos la muestra en 10 subconjuntos (`k = 10`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k <- 10\n",
    "# Número de registros (instancias u observaciones) en nuestro dataset.\n",
    "n <- nrow(europe) \n",
    "# factor de números aleatorios con k levels (del 1 al 10) \n",
    "set.seed(1)\n",
    "split.factor <- sample(rep(1:10, each = ceiling(n/k)), n) \n",
    "# Lista que en cada \"slot\" contiene un fold \n",
    "spl.europe <- split(europe, f = split.factor)\n",
    "str(spl.europe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) ajustamos el modelo con la función `lm` con `k-1` y predecimos (función `predict`) sobre el fold restante. Se repite la operación `k` veces (en un bucle lapply):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yest.3 <- lapply(1:k, function(x) {\n",
    "  reg.3 <- lm(weight~horsepower, data = do.call(\"rbind\", spl.europe[-x]))\n",
    "  predict(reg.3, data.frame(horsepower = spl.europe[[x]]$horsepower))\n",
    "})\n",
    "str(yest.3)\n",
    "# Hacemos un plot de los valores de weight rales frente a los estimados \n",
    "plot(do.call(\"rbind\", spl.europe)$weight, typ = \"l\")\n",
    "lines(do.call(\"c\", yest.3), col = \"red\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Calculamos el error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# de cada fold\n",
    "rmse.val.3.folds <- lapply(1:length(spl.europe), function(x) rmse(spl.europe[[x]]$weight, yest.3[[x]]))\n",
    "# de la muestra entera\n",
    "rmse.val.3 <- rmse(do.call(\"rbind\", spl.europe)$weight, do.call(\"c\", yest.3))\n",
    "plot(do.call(\"c\", rmse.val.3.folds), ylab = \"rmse\", xlab = \"fold\", pch = \"x\", ylim = c(0, 400), col = \"red\")\n",
    "abline(h = rmse.val.3, col = \"red\")\n",
    "abline(h = rmse(obs = europe$weight, yest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Práctica 1\n",
    "\n",
    "¿Es el modelo aprendido con los registros europeos adecuado para estimar el peso de los coches americanos? (¿qué ocurre cuando aplicamos el modelo a la muestra de test (objeto `america`)?)\n",
    "\n",
    "Utiliza las funciones de visualización (`plot`, `points`, `lines`, `abline`, ...) para ilustrar los resultados.\n",
    "\n",
    "Escribe el código a continuación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg.3.all <- lm(weight~horsepower, data = europe)\n",
    "#(...)\n",
    "\n",
    "plot(do.call(\"c\", rmse.val.3.folds), ylab = \"rmse\", xlab = \"fold\", pch = \"x\", ylim = c(0, 400))# error de validación obtenido anteriormente para cada fold\n",
    "abline(h = rmse.val.3)# error de validación global (de todos los folds) obtenido anteriormente \n",
    "\n",
    "# abline(...\n",
    "\n",
    "#(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Práctica 2\n",
    "\n",
    "Utiliza la librería caret para reproducir el último ejemplo de cross-validación con k-fold y obtén el error de validación global.\n",
    "\n",
    "Escribe el código a continuación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Práctica 3\n",
    "\n",
    "Utiliza los datos de los coches americanos para estimar los pesos de los coches europeos por un lado y la de los japoneses por otro.\n",
    "\n",
    "¿Es el modelo aprendido adecuado para estimar el peso de los coches europeos y japoneses?\n",
    "\n",
    "Utiliza caret y las funciones de visualización (`plot`, `points`, `lines`, `abline`, ...) para ilustrar los resultados. \n",
    "\n",
    "Escribe el código a continuación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
